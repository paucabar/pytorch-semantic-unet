{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import UNET\n",
    "from utils import (\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    get_loaders,\n",
    "    check_accuracy,\n",
    "    show_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 200\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 1024\n",
    "IMAGE_WIDTH = 1024\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "TRAIN_IMG_DIR = \"data/train_images/\"\n",
    "TRAIN_MASK_DIR = \"data/train_masks/\"\n",
    "VAL_IMG_DIR = \"data/val_images/\"\n",
    "VAL_MASK_DIR = \"data/val_masks/\"\n",
    "SHOW_VAL_INTERVAL = 100\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU access\n",
    "print(torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory}\")\n",
    "else:\n",
    "    print(\"No GPU\")\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images =[]\n",
    "for file in glob.glob(TRAIN_IMG_DIR + \"\\*.tif\"):\n",
    "    all_images.append(os.path.basename(file))\n",
    "\n",
    "#print(all_images)\n",
    "\n",
    "# Load image example\n",
    "img_filename = os.path.join(TRAIN_IMG_DIR, all_images[0])\n",
    "image_example = io.imread(img_filename)\n",
    "#image_example.astype(np.uint8)\n",
    "    \n",
    "# Load mask example\n",
    "mask_filename = os.path.join(TRAIN_MASK_DIR, all_images[0])\n",
    "mask_example = io.imread(mask_filename)\n",
    "\n",
    "# define RGB colors from Tableau 10 (default in matplotlib)\n",
    "t10_blue = [31/255, 119/255, 180/255]\n",
    "t10_orange = [255/255, 127/255, 14/255]\n",
    "t10_green = [44/255, 160/255, 44/255]\n",
    "t10_red = [214/255, 39/255, 40/255]\n",
    "\n",
    "# list of colors\n",
    "colors=[t10_blue, t10_orange, t10_green, t10_red]\n",
    "\n",
    "rgb_labels = label2rgb(\n",
    "    label=mask_example[0:IMAGE_HEIGHT,0:IMAGE_WIDTH],\n",
    "    image=image_example[0:IMAGE_HEIGHT,0:IMAGE_WIDTH],\n",
    "    colors=colors,\n",
    "    alpha=0.7,\n",
    "    bg_label=0,\n",
    "    bg_color=None\n",
    "    )\n",
    "\n",
    "# plot pair example and overlay\n",
    "fig, ax = plt.subplots(1,3, figsize=(18,6))\n",
    "fig.suptitle(\"Training data example\\n\" + all_images[0])\n",
    "ax[0].imshow(image_example[0:IMAGE_HEIGHT,0:IMAGE_WIDTH], cmap='gray')\n",
    "ax[0].set_title(\"Image\")\n",
    "ax[1].imshow(mask_example[0:IMAGE_HEIGHT,0:IMAGE_WIDTH])\n",
    "ax[1].set_title(\"Mask\")\n",
    "ax[2].imshow(rgb_labels)\n",
    "ax[2].set_title(\"Overlay\")\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "    train_loss_all= []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        #targets = targets.float().unsqueeze(1).to(device=DEVICE) # unsqueeze(1) to add a channel dimension\n",
    "        targets = targets.type(torch.LongTensor).to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            train_loss = loss_fn(predictions, targets)\n",
    "            if DEBUG:\n",
    "                print(\"DEBUG!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                m = nn.Softmax(dim=None)\n",
    "                smax = m(predictions[0:1])\n",
    "                argmax = torch.argmax(smax, dim=1)\n",
    "                show_images(data[0:1], targets[0:1], argmax, smax[:,0], smax[:,1], smax[:,2], smax[:,3], smax[:,4], smax[:,5], titles=[\"Image\", \"Target\", \"Prediction\", \"Background Probability\", \"Myelin Probability\", \"Tongue Probability\", \"AxonM Probability\", \"AxonNM Probability\", \"Mitochondria Probability\"],n_cols=3)\n",
    "    \n",
    "                #show_images(predictions,predictions>0,targets,titles=[\"Prediction\",\"Threshold\",\"Label\"])\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(train_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(train_loss=train_loss.item())\n",
    "        train_loss_all.append(train_loss.item())\n",
    "    \n",
    "    return sum(train_loss_all)/len(train_loss_all)\n",
    "\n",
    "def transforms_fn():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            #A.RandomScale(scale_limit=0.2, interpolation=cv2.INTER_LINEAR, p=0.1),\n",
    "            #A.Rotate(limit=90, p=0.25, border_mode=cv2.BORDER_CONSTANT),\n",
    "            A.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            #A.OneOf([\n",
    "            #    A.GaussianBlur (blur_limit=(3, 5), sigma_limit=0, always_apply=False, p=0.25),\n",
    "            #    A.MedianBlur (blur_limit=3, always_apply=False, p=0.25),\n",
    "            #    A.GaussNoise(var_limit=(0.05, 0.1), mean=0, per_channel=True, always_apply=False, p=0.25),\n",
    "            #    A.Defocus (radius=(1, 15), alias_blur=(0.1, 0.5), always_apply=False, p=0.25)\n",
    "            #], p=0.2),\n",
    "            A.Normalize(\n",
    "                mean=[0.0],\n",
    "                std=[1.0],\n",
    "                max_pixel_value=200000.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    val_transforms = A.Compose(\n",
    "        [\n",
    "            A.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(\n",
    "                mean=[0.0],\n",
    "                std=[1.0],\n",
    "                max_pixel_value=200000.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return train_transform, val_transforms\n",
    "\n",
    "def loss_plot_fn(train_loss, val_loss):\n",
    "    # plot train and val loss\n",
    "    print(\"\\n----------------------------------------------------------------------------\")\n",
    "    print(\"\\nTraining and validation loss\")\n",
    "    \n",
    "    fig_loss = plt.gcf()\n",
    "    \n",
    "    plt.plot(np.arange(1,len(train_loss)+1).tolist(), train_loss, label = \"Training loss\")\n",
    "    plt.plot(np.arange(1,len(val_loss)+1).tolist(), val_loss, label = \"Validation loss\")\n",
    "    plt.title('Training and validation loss vs epoch number (linear)')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.ylim(0,2)\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.xticks(ticks=np.arange(0, len(val_loss)+1, (len(val_loss))/4).tolist())\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    fig_loss.set_facecolor('white')\n",
    "    fig_loss.savefig('loss_plot.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from dataset import BinaryDataset\n",
    "\n",
    "\n",
    "def visualize_augmentations(dataset, idx=0, samples=10, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(16, 8))\n",
    "    for i in range(samples):\n",
    "        image, _ = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "train_transform, val_transforms = transforms_fn()\n",
    "train_dataset = BinaryDataset(image_dir=TRAIN_IMG_DIR, mask_dir=TRAIN_MASK_DIR, transform=train_transform)\n",
    "\n",
    "random.seed(42)\n",
    "visualize_augmentations(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_transform, val_transforms = transforms_fn()\n",
    "    \n",
    "    model = UNET(in_channels=1, out_channels=6).to(DEVICE)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # for multilabel segmentation change out_channels (e.g., 3) and use cross entropy loss insted of BCEWithLogitsLoss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        BATCH_SIZE,\n",
    "        train_transform,\n",
    "        val_transforms,\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        last_epoch, train_loss, val_loss = load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "        check_accuracy(val_loader, model, device=DEVICE, show_results=True)\n",
    "        print(\"Model successfully loaded\")\n",
    "    else:\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        last_epoch = 0\n",
    "        print(\"Training model from scratch\")\n",
    "\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "    if (SHOW_VAL_INTERVAL > 0):\n",
    "        display_check = np.arange(SHOW_VAL_INTERVAL-1, NUM_EPOCHS, SHOW_VAL_INTERVAL)\n",
    "    else:\n",
    "        display_check = 0\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"\\n----------------------------------------------------------------------------\")\n",
    "        print(f\"\\nepoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        if LOAD_MODEL:\n",
    "            print(f\"total epoch {last_epoch+epoch+1}/{last_epoch+NUM_EPOCHS}\")\n",
    "        \n",
    "        # train model\n",
    "        t_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "        train_loss.append(t_loss)\n",
    "\n",
    "        # check accuracy\n",
    "        show_results = np.any(display_check == epoch)\n",
    "        v_loss = check_accuracy(val_loader, model, device=DEVICE, show_results=show_results)\n",
    "        val_loss.append(v_loss)\n",
    "\n",
    "        # save model checkpoint\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch + 1 + last_epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "        # print some examples to a folder\n",
    "        #save_predictions_as_imgs(\n",
    "        #    val_loader, model, folder=\"saved_images/\", device=DEVICE\n",
    "        #)\n",
    "\n",
    "\n",
    "    loss_plot_fn(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39beb5368577c04a016fb520a62a16077a6043242662db884d574d69cb028cf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
